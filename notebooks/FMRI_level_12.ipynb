{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.algorithms.modelgen as model\n",
    "from config import root\n",
    "from IPython.display import Image\n",
    "\n",
    "fsl.FSLCommand.set_default_output_type(\"NIFTI_GZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contrasts(contrasts, names, con_type=\"T\", show_output=True):\n",
    "    \"\"\"Make contrasts as read into FSL\"\"\"\n",
    "\n",
    "    contrasts_fmt = []\n",
    "    for contrast in contrasts:\n",
    "\n",
    "        # create contrast title\n",
    "        title_left, title_right = [], []\n",
    "        for k, v in contrast.items():\n",
    "            title_left += [k] if v > 0 else []\n",
    "            title_right += [k] if v < 0 else []\n",
    "        title = \", \".join(title_left) + \" > \" + \", \".join(title_right)\n",
    "\n",
    "        weights_per_regr = []\n",
    "        for name in names:\n",
    "            weight = contrast[name] if name in contrast.keys() else 0\n",
    "            weights_per_regr.append(weight)\n",
    "\n",
    "        contrasts_fmt.append((title, con_type, names, weights_per_regr))\n",
    "\n",
    "    if show_output:\n",
    "        for con in contrasts_fmt:\n",
    "            print(\"=\"*20)\n",
    "            print(con[0])\n",
    "            print(\"-\"*20)\n",
    "            print(con[1])\n",
    "            for reg, weight in zip(con[2], con[3]):\n",
    "                print(reg, \"\\t\", weight)\n",
    "            print(\"=\"*20)\n",
    "            print(\"\\n\")\n",
    "\n",
    "    return contrasts_fmt\n",
    "\n",
    "def pop_decay(in_file=\"\", duration=.2, **kwargs):\n",
    "\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    import pandas as pd\n",
    "\n",
    "    # the data\n",
    "    regs = pd.read_csv(in_file, header=0)\n",
    "    conditions = regs.columns.tolist()\n",
    "    conditions.remove(\"onset\")\n",
    "    onsets = [regs.onset] * len(conditions)\n",
    "    durations = [ [duration] * len(regs) ] * len(conditions)\n",
    "    amplitudes = regs[conditions].values.T.tolist()\n",
    "    \n",
    "    output = Bunch(conditions=conditions, onsets=onsets,\n",
    "                   durations=durations, amplitudes=amplitudes)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathnames\n",
    "base_dir = os.path.join(root, \"data\")\n",
    "output_dir = os.path.join(root, \"data\", \"output\")\n",
    "working_dir = os.path.join(root, \"data\", \"working_dir\")\n",
    "\n",
    "# MNI standard file\n",
    "standard = os.path.join(root, \"data\", \"in_analysis\", \"nii\", \"standard\")\n",
    "mni_standard_path = os.path.join(standard, \"MNI152_T1_2mm_brain.nii.gz\")\n",
    "mni_brain_standard_path = os.path.join(standard, \"MNI152_T1_2mm_brain.nii.gz\")\n",
    "mni_brain_mask_standard_path = os.path.join(standard, \"MNI152_T1_2mm_brain_mask.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "glm_prefix = \"pop_decay_submean_\"\n",
    "TR = 2.1\n",
    "filter_cutoff = 60\n",
    "\n",
    "# Lists\n",
    "sub_list = [\"sub_%03d\" % i for i in range(1, 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over subjects\n",
    "infosource = pe.Node(\n",
    "    util.IdentityInterface(\n",
    "        fields=[\"sub_id\"]),\n",
    "    name=\"infosource\")\n",
    "\n",
    "# Define iterable attributes\n",
    "infosource.iterables = [(\"sub_id\", sub_list)]\n",
    "\n",
    "# File templates for different subjects and sessions\n",
    "templates = {\n",
    "    \"runs\"       : \"output/highpass/ses_*{sub_id}/_hp_filter*/run_*_st_mcf_warp_dtype_bet_intnorm_smooth_hpf.nii.gz\",    \n",
    "#     \"runs\"       : \"output/subtractmean/ses_*{sub_id}/_subtractmean*/run_*_st_mcf_warp_dtype_bet_intnorm_smooth_hpf_sub.nii.gz\",\n",
    "    \"behavior\"   : \"search/regs/{sub_id}_ses_*_scn_*.txt\",\n",
    "    \"func1\"      : \"output/highpass/ses_000{sub_id}/_hp_filter0/run_000_st_mcf_warp_dtype_bet_intnorm_smooth_hpf.nii.gz\",\n",
    "    \"warp_field\" : \"output/register_to_standard/{sub_id}/orig_field.nii.gz\", \n",
    "    \"premat\"     : \"output/register_to_standard/{sub_id}/inplane_brain_bbreg_{sub_id}.mat\",\n",
    "}\n",
    "\n",
    "# SelectFiles Node to handle session specific file templates\n",
    "files = pe.Node(\n",
    "    SelectFiles(\n",
    "        templates,\n",
    "        base_directory=base_dir,\n",
    "        sort_filelist=True),\n",
    "    name=\"files\")\n",
    "\n",
    "# Create datasink to store important\n",
    "# files in useful, more accessable locations.\n",
    "datasink = pe.Node(\n",
    "    DataSink(\n",
    "        base_directory=base_dir,\n",
    "        container=\"output\"),\n",
    "    name=\"datasink\")\n",
    "\n",
    "# Remove unwanted lengthy strings from filenames.\n",
    "datasink.inputs.substitutions = [(\"_sub_id_\", \"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = [{\n",
    "    'loc1': 1,\n",
    "    'loc2': -0.3333333333333333,\n",
    "    'loc3': -0.3333333333333333,\n",
    "    'loc4': -0.3333333333333333\n",
    "}, {\n",
    "    'loc2': 1,\n",
    "    'loc1': -0.3333333333333333,\n",
    "    'loc3': -0.3333333333333333,\n",
    "    'loc4': -0.3333333333333333\n",
    "}, {\n",
    "    'loc3': 1,\n",
    "    'loc1': -0.3333333333333333,\n",
    "    'loc2': -0.3333333333333333,\n",
    "    'loc4': -0.3333333333333333\n",
    "}, {\n",
    "    'loc4': 1,\n",
    "    'loc1': -0.3333333333333333,\n",
    "    'loc2': -0.3333333333333333,\n",
    "    'loc3': -0.3333333333333333\n",
    "}, {\n",
    "    'loc_lag1': 0.5, \n",
    "    'loc_lag2': 0.5,\n",
    "}, {\n",
    "    'loc_lag1': 1.0\n",
    "}, {\n",
    "    'loc_lag2': 1.0,\n",
    "}, {\n",
    "    'clr_lag1': 0.5, \n",
    "    'clr_lag2': 0.5,\n",
    "}, {\n",
    "    'clr_lag1': 1.0\n",
    "}, {\n",
    "    'clr_lag2': 1.0\n",
    "}, {\n",
    "    'loc1': 0.25, \n",
    "    'loc2': 0.25, \n",
    "    'loc3': 0.25, \n",
    "    'loc4': 0.25\n",
    "}]\n",
    "\n",
    "conditions = [\"loc1\", \"loc2\", \"loc3\", \"loc4\",\n",
    "              \"loc_lag1\", \"loc_lag2\",\n",
    "              \"clr_lag1\", \"clr_lag2\"]\n",
    "\n",
    "# Create contrasts for FSL\n",
    "contrasts_large = make_contrasts(contrasts, conditions, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_function = pe.MapNode(\n",
    "    util.Function(\n",
    "        input_names=[\"in_file\"],\n",
    "        output_names=[\"subject_info\"],\n",
    "        function=pop_decay),\n",
    "    iterfield=[\"in_file\"],\n",
    "    name=glm_prefix+\"glm_function\")\n",
    "\n",
    "# Specify model\n",
    "specifymodel = pe.Node(\n",
    "    model.SpecifyModel(\n",
    "        high_pass_filter_cutoff=filter_cutoff,\n",
    "        time_repetition=TR,\n",
    "        input_units=\"secs\",\n",
    "    ), \n",
    "    name=glm_prefix+\"specifymodel\"\n",
    ")\n",
    "\n",
    "# Level 1 design\n",
    "level1design = pe.Node(\n",
    "    fsl.Level1Design(\n",
    "        bases={\"dgamma\" : {\"derivs\": True}},\n",
    "        interscan_interval=TR,\n",
    "        model_serial_correlations=True, # Prewhitening\n",
    "        contrasts=contrasts_large,\n",
    "    ), \n",
    "    name=glm_prefix+\"level1design\"\n",
    ")\n",
    "\n",
    "# model\n",
    "featmodel = pe.MapNode(\n",
    "    interface=fsl.FEATModel(),\n",
    "    name=glm_prefix+\"featmodel_ses1\",\n",
    "    iterfield=[\"fsf_file\", \"ev_files\"]\n",
    ")\n",
    "\n",
    "# FILMGLS\n",
    "filmgls = pe.MapNode(\n",
    "    interface=fsl.FILMGLS(\n",
    "        threshold=-1500,\n",
    "    ),\n",
    "    iterfield=[\"design_file\", \"in_file\", \"tcon_file\"],\n",
    "    name=glm_prefix+\"filmgls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstlevel = pe.Workflow(name=glm_prefix+\"firstlevel\", base_dir=working_dir)\n",
    "\n",
    "firstlevel.connect(glm_function, \"subject_info\", specifymodel, \"subject_info\")\n",
    "firstlevel.connect(specifymodel, \"session_info\", level1design, \"session_info\")\n",
    "firstlevel.connect(level1design, \"fsf_files\", featmodel, \"fsf_file\")\n",
    "firstlevel.connect(level1design, \"ev_files\", featmodel, \"ev_files\")\n",
    "firstlevel.connect(featmodel, \"design_file\", filmgls, \"design_file\")\n",
    "firstlevel.connect(featmodel, \"con_file\", filmgls, \"tcon_file\")\n",
    "\n",
    "firstlevel.write_graph(simple_form=True, graph2use=\"hierarchical\", dotfilename=\"./graph_hierarchical.dot\")\n",
    "\n",
    "# Visualize graph\n",
    "Image(width=768, filename=\"graph_hierarchical.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contrasts = len(contrasts)\n",
    "con_list = [\"%d\" % (i+1) for i in range(num_contrasts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanfunc = pe.Node(\n",
    "    interface=fsl.ImageMaths(\n",
    "        op_string=\"-Tmean\",\n",
    "        suffix=\"_mean\"),\n",
    "    name=\"meanfunc\")\n",
    "\n",
    "meanfuncmask = pe.Node(\n",
    "    interface=fsl.BET(\n",
    "        mask=True,\n",
    "        no_output=True,\n",
    "        frac=0.05),\n",
    "    name=\"meanfuncmask\")\n",
    "\n",
    "dilatemask = pe.Node(\n",
    "    interface=fsl.ImageMaths(\n",
    "        suffix=\"_dil\",\n",
    "        op_string=\"-dilF\"),\n",
    "    name=\"dilatemask\")\n",
    "\n",
    "# Concatenate copes before feeding to Flameo\n",
    "merge_copes = pe.MapNode(\n",
    "    interface=fsl.Merge(\n",
    "        dimension=\"t\"),\n",
    "    iterfield=[\"in_files\"],\n",
    "    name=\"merge_copes\")\n",
    "\n",
    "merge_varcopes = pe.MapNode(\n",
    "    interface=fsl.Merge(\n",
    "        dimension=\"t\"),\n",
    "    iterfield=[\"in_files\"],\n",
    "    name=\"merge_varcopes\")\n",
    "\n",
    "# Create a level2 model\n",
    "l2model_fixed = pe.Node(\n",
    "    interface=fsl.L2Model(), \n",
    "    name=\"l2model_fixed\")\n",
    "\n",
    "# A fixed effects FLAMEO node, with copes and varcopes as inputs.\n",
    "fixed_flameo = pe.MapNode(\n",
    "    interface=fsl.FLAMEO(\n",
    "        run_mode=\"fe\"),\n",
    "    iterfield=[\"cope_file\", \"var_cope_file\"],\n",
    "    name=\"fixed_flameo\")\n",
    "\n",
    "applywarp_copes = pe.MapNode(\n",
    "    fsl.ApplyWarp(\n",
    "        ref_file=mni_standard_path),\n",
    "    iterfield=[\"in_file\"],\n",
    "    name=\"applywarp_copes\",\n",
    "    overwrite=False)\n",
    "\n",
    "applywarp_varcopes = pe.MapNode(\n",
    "    fsl.ApplyWarp(\n",
    "        ref_file=mni_standard_path),\n",
    "    iterfield=[\"in_file\"],\n",
    "    name=\"applywarp_varcopes\",\n",
    "    overwrite=False)\n",
    "\n",
    "applywarp_zstats = pe.MapNode(\n",
    "    fsl.ApplyWarp(\n",
    "        ref_file=mni_standard_path),\n",
    "    iterfield=['in_file'],\n",
    "    name='applywarp_zstats',\n",
    "    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_fx = pe.Workflow(name=glm_prefix+\"fixed_fx\", base_dir=working_dir)\n",
    "\n",
    "def num_copes(files):\n",
    "    return len(files)\n",
    "\n",
    "fixed_fx.connect(meanfunc, \"out_file\", meanfuncmask, \"in_file\")\n",
    "fixed_fx.connect(meanfuncmask, \"mask_file\", dilatemask, \"in_file\")\n",
    "fixed_fx.connect(dilatemask, \"out_file\", fixed_flameo, \"mask_file\")\n",
    "fixed_fx.connect(merge_copes, \"merged_file\", fixed_flameo, \"cope_file\")\n",
    "fixed_fx.connect(merge_varcopes, \"merged_file\", fixed_flameo, \"var_cope_file\")\n",
    "fixed_fx.connect(l2model_fixed, \"design_mat\", fixed_flameo, \"design_file\")\n",
    "fixed_fx.connect(l2model_fixed, \"design_con\", fixed_flameo, \"t_con_file\")\n",
    "fixed_fx.connect(l2model_fixed, \"design_grp\", fixed_flameo, \"cov_split_file\")\n",
    "fixed_fx.connect(fixed_flameo, \"copes\", applywarp_copes, \"in_file\")\n",
    "fixed_fx.connect(fixed_flameo, \"var_copes\", applywarp_varcopes, \"in_file\")\n",
    "fixed_fx.connect(fixed_flameo, \"zstats\", applywarp_zstats, \"in_file\")\n",
    "\n",
    "fixed_fx.write_graph(simple_form=True, graph2use=\"hierarchical\", dotfilename=\"./graph_hierarchical.dot\")\n",
    "Image(width=768, filename=\"graph_hierarchical.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = pe.Workflow(name=\"glm_submean\", base_dir=working_dir)\n",
    "\n",
    "# Inputs first level\n",
    "glm.connect(files, \"behavior\", firstlevel, glm_prefix+\"glm_function.in_file\")\n",
    "glm.connect(files, \"runs\", firstlevel, glm_prefix+\"specifymodel.functional_runs\")\n",
    "glm.connect(files, \"runs\", firstlevel, glm_prefix+\"filmgls.in_file\")\n",
    "glm.connect(files, \"func1\", fixed_fx, \"meanfunc.in_file\")\n",
    "\n",
    "# Inputs warp\n",
    "glm.connect(infosource, \"sub_id\", files, \"sub_id\")\n",
    "glm.connect(files, \"premat\", fixed_fx, \"applywarp_copes.premat\")\n",
    "glm.connect(files, \"warp_field\", fixed_fx, \"applywarp_copes.field_file\")\n",
    "glm.connect(files, \"premat\", fixed_fx, \"applywarp_varcopes.premat\")\n",
    "glm.connect(files, \"warp_field\", fixed_fx, \"applywarp_varcopes.field_file\")\n",
    "glm.connect(files, \"premat\", fixed_fx, \"applywarp_zstats.premat\")\n",
    "glm.connect(files, \"warp_field\", fixed_fx, \"applywarp_zstats.field_file\")\n",
    "\n",
    "def sort_copes(files):\n",
    "    numelements = len(files[0])\n",
    "    outfiles = []\n",
    "    for i in range(numelements):\n",
    "        outfiles.insert(i,[])\n",
    "        for j, elements in enumerate(files):\n",
    "            outfiles[i].append(elements[i])\n",
    "    return outfiles\n",
    "\n",
    "def num_copes(files):\n",
    "    return len(files)\n",
    "\n",
    "# Connect first to second level\n",
    "glm.connect(firstlevel, (glm_prefix+\"filmgls.copes\", sort_copes), fixed_fx, \"merge_copes.in_files\")\n",
    "glm.connect(firstlevel, (glm_prefix+\"filmgls.varcopes\", sort_copes), fixed_fx, \"merge_varcopes.in_files\")\n",
    "glm.connect(firstlevel, (glm_prefix+\"filmgls.copes\", num_copes), fixed_fx, \"l2model_fixed.num_copes\")\n",
    "\n",
    "# Outputs Level 1\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.zstats\", datasink, glm_prefix+\"filmgls.@zstats\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.param_estimates\", datasink, glm_prefix+\"filmgls.@param_estimates\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.copes\", datasink, glm_prefix+\"filmgls.@copes\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.varcopes\", datasink, glm_prefix+\"filmgls.@varcopes\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.dof_file\", datasink, glm_prefix+\"filmgls.@dof_file\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.logfile\", datasink, glm_prefix+\"filmgls.@logfile\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.residual4d\", datasink, glm_prefix+\"filmgls.@residual4d\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.sigmasquareds\", datasink, glm_prefix+\"filmgls.@sigmasquareds\")\n",
    "glm.connect(firstlevel, glm_prefix+\"filmgls.tstats\", datasink, glm_prefix+\"filmgls.@tstats\")\n",
    "\n",
    "# Outputs Level 2\n",
    "glm.connect(fixed_fx, \"dilatemask.out_file\", datasink, glm_prefix + \"L2_fixedfx\"+\".funcmask\")\n",
    "glm.connect(fixed_fx, \"fixed_flameo.copes\", datasink, glm_prefix + \"L2_fixedfx\"+\".copes\")\n",
    "glm.connect(fixed_fx, \"fixed_flameo.var_copes\", datasink, glm_prefix + \"L2_fixedfx\"+\".varcopes\")\n",
    "glm.connect(fixed_fx, \"fixed_flameo.zstats\", datasink, glm_prefix + \"L2_fixedfx\"+\".zstats\")\n",
    "glm.connect(fixed_fx, \"applywarp_copes.out_file\", datasink, glm_prefix + \"L2_fixedfx\"+\"_warped\"+\".copes\")\n",
    "glm.connect(fixed_fx, \"applywarp_varcopes.out_file\", datasink, glm_prefix + \"L2_fixedfx\"+\"_warped\"+\".varcopes\")\n",
    "glm.connect(fixed_fx, \"applywarp_zstats.out_file\", datasink, glm_prefix + \"L2_fixedfx\"+\"_warped\"+\".zstats\")\n",
    "\n",
    "glm.write_graph(\n",
    "    simple_form=True, \n",
    "    graph2use=\"hierarchical\", \n",
    "    dotfilename=\"./graph_hierarchical.dot\"\n",
    ")\n",
    "\n",
    "Image(width=768, filename=\"graph_hierarchical.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.run(plugin='MultiProc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
