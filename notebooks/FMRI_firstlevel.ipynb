{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.algorithms.modelgen as model\n",
    "from config import root\n",
    "\n",
    "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contrasts(contrasts, names, con_type='T', show_output=True):\n",
    "    \"\"\"Make contrasts as read into FSL\"\"\"\n",
    "\n",
    "    contrasts_fmt = []\n",
    "    for contrast in contrasts:\n",
    "\n",
    "        # create contrast title\n",
    "        title_left, title_right = [], []\n",
    "        for k, v in contrast.items():\n",
    "            title_left += [k] if v > 0 else []\n",
    "            title_right += [k] if v < 0 else []\n",
    "        title = ', '.join(title_left) + ' > ' + ', '.join(title_right)\n",
    "\n",
    "        weights_per_regr = []\n",
    "        for name in names:\n",
    "            weight = contrast[name] if name in contrast.keys() else 0\n",
    "            weights_per_regr.append(weight)\n",
    "\n",
    "        contrasts_fmt.append((title, con_type, names, weights_per_regr))\n",
    "\n",
    "    if show_output:\n",
    "        for con in contrasts_fmt:\n",
    "            print('='*20)\n",
    "            print(con[0])\n",
    "            print('-'*20)\n",
    "            print(con[1])\n",
    "            for reg, weight in zip(con[2], con[3]):\n",
    "                print(reg, '\\t', weight)\n",
    "            print('='*20)\n",
    "            print('\\n')\n",
    "\n",
    "    return contrasts_fmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathnames\n",
    "base_dir = os.path.join(root, \"data\")\n",
    "output_dir = os.path.join(root, \"data\", \"output\")\n",
    "working_dir = os.path.join(root, \"data\", \"working_dir\")\n",
    "mni_standard_path = os.path.join(root, \"data\", \"in_analysis\", \"standard\", \"nii/misc/MNI152_T1_1mm_brain.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "glm_prefix = 'pop_decay_'\n",
    "TR = 2.1\n",
    "filter_cutoff = 60\n",
    "\n",
    "# Lists\n",
    "sub_list = ['sub_%03d' % i for i in range(1, 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over subjects\n",
    "infosource = pe.Node(\n",
    "    util.IdentityInterface(\n",
    "        fields=['sub_id']),\n",
    "    name='infosource')\n",
    "\n",
    "# Define iterable attributes\n",
    "infosource.iterables = [('sub_id', sub_list)]\n",
    "\n",
    "# File templates for different subjects and sessions\n",
    "templates = {\n",
    "    \"runs\"     : \"output/highpass/ses_*{sub_id}/_hp_filter*/run_*_st_mcf_warp_bet_smooth_hpf.nii.gz\",\n",
    "    \"behavior\" : \"search/regs/{sub_id}/ses_*/run_*.txt\"\n",
    "}\n",
    "\n",
    "# SelectFiles Node to handle session specific file templates\n",
    "files = pe.Node(\n",
    "    SelectFiles(templates,\n",
    "                base_directory=base_dir,\n",
    "                sort_filelist=True),\n",
    "                name='files')\n",
    "\n",
    "# Create datasink to store important\n",
    "# files in useful, more accessable locations.\n",
    "datasink = pe.Node(\n",
    "    DataSink(\n",
    "        base_directory=base_dir,\n",
    "        container=\"output\"),\n",
    "    name='datasink')\n",
    "\n",
    "# Remove unwanted lengthy strings from filenames.\n",
    "datasink.inputs.substitutions = [('_sub_id_', ''),\n",
    "                                 ('_ses_id_', '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [('loc1', 'loc2', 'loc3', 'loc4'),\n",
    "              ('loc_lag1', 'loc_lag2'),\n",
    "              ('clr_lag1', 'clr_lag2')]\n",
    "\n",
    "# Location contrasts\n",
    "contrasts = []\n",
    "for cons in conditions[:1]:\n",
    "    for i, con in enumerate(cons):\n",
    "        this = i\n",
    "        other = list(range(len(cons)))\n",
    "        other.remove(i)\n",
    "\n",
    "        dct = {cons[this]: 1}\n",
    "        dct.update({cons[i]: -1.0 / len(other) for i in other})\n",
    "        contrasts.append(dct)\n",
    "\n",
    "# Priming contrasts\n",
    "for cons in conditions[1:]:\n",
    "    contrasts.append({con: 1.0/len(cons) for con in cons})\n",
    "    contrasts += [{con: 1.0} for con in cons]\n",
    "\n",
    "# Stimulus onset baseline\n",
    "contrasts.append({con:.25 for con in conditions[0]})\n",
    "\n",
    "conditions = [loc for con in conditions for loc in con]\n",
    "\n",
    "# Create contrasts for FSL\n",
    "contrasts_large = make_contrasts(contrasts, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_function = pe.MapNode(\n",
    "    util.Function(\n",
    "        input_names=['in_file'],\n",
    "        output_names=['subject_info'],\n",
    "        function=pop_decay),\n",
    "    iterfield=['in_file'],\n",
    "    name=glm_prefix+'glm_function')\n",
    "\n",
    "# Specify model\n",
    "specifymodel = pe.Node(\n",
    "    model.SpecifyModel(\n",
    "        high_pass_filter=filter_cutoff,\n",
    "        time_repetition=TR,\n",
    "        intput_units=\"secs\",\n",
    "    ), \n",
    "    name=glm_prefix+'specifymodel'\n",
    ")\n",
    "\n",
    "# Level 1 design\n",
    "level1design = pe.Node(\n",
    "    fsl.Level1Design(\n",
    "        bases={\"dgamma\" : {\"derivs\": True}},\n",
    "        interscan_interval=TR,\n",
    "        model_serial_correlations=True, # Prewhitening\n",
    "        contrasts=contrasts_large,\n",
    "    ), \n",
    "    name=glm_prefix+'level1design',\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "# model\n",
    "featmodel = pe.MapNode(\n",
    "    interface=fsl.FEATModel(),\n",
    "    name=glm_prefix+'featmodel_ses1',\n",
    "    iterfield=['fsf_file', 'ev_files']\n",
    ")\n",
    "\n",
    "# FILMGLS\n",
    "filmgls = pe.MapNode(\n",
    "    interface=fsl.FILMGLS(\n",
    "        threshold=10\n",
    "    ),\n",
    "    iterfield=['design_file', 'in_file', 'tcon_file'],\n",
    "    name=glm_prefix+'filmgls',\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% connect nodes\n",
    "modelfit = pe.Workflow(name=glm_prefix+'modelfit')\n",
    "modelfit.connect(files, 'behavior', glm_function, 'in_file')\n",
    "modelfit.connect(files, 'params_clr', glm_function, 'params_clr')\n",
    "modelfit.connect(files, 'params_loc', glm_function, 'params_loc')\n",
    "modelfit.connect(glm_function, 'subject_info', specifymodel, 'subject_info')\n",
    "modelfit.connect(specifymodel, 'session_info', level1design, 'session_info')\n",
    "modelfit.connect(level1design, 'fsf_files', featmodel, 'fsf_file')\n",
    "modelfit.connect(level1design, 'ev_files', featmodel, 'ev_files')\n",
    "modelfit.connect(featmodel, 'design_file', filmgls, 'design_file')\n",
    "modelfit.connect(featmodel, 'con_file', filmgls, 'tcon_file')\n",
    "\n",
    "# %% Level 1\n",
    "firstlevel = pe.Workflow(name='firstlevel',\n",
    "                         base_dir=working_dir)\n",
    "\n",
    "# Connect coregistration output to functional runs model specification\n",
    "firstlevel.connect(preproc, 'subtract_mean.out_file',\n",
    "                   modelfit, glm_prefix+'specifymodel.functional_runs')\n",
    "\n",
    "# Connect coregistration output to model estimate input\n",
    "firstlevel.connect(preproc, 'subtract_mean.out_file',\n",
    "                   modelfit, glm_prefix+'filmgls.in_file')\n",
    "\n",
    "#==============================================================================\n",
    "# Outputs to output folder\n",
    "#==============================================================================\n",
    "\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.zstats', datasink, glm_prefix+'filmgls.@zstats')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.param_estimates', datasink, glm_prefix+'filmgls.@param_estimates')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.copes', datasink, glm_prefix+'filmgls.@copes')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.varcopes', datasink, glm_prefix+'filmgls.@varcopes')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.dof_file', datasink, glm_prefix+'filmgls.@dof_file')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.logfile', datasink, glm_prefix+'filmgls.@logfile')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.residual4d', datasink, glm_prefix+'filmgls.@residual4d')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.sigmasquareds', datasink, glm_prefix+'filmgls.@sigmasquareds')\n",
    "firstlevel.connect(modelfit, glm_prefix+'filmgls.tstats', datasink, glm_prefix+'filmgls.@tstats')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #firstlevel.write_graph()\n",
    "    firstlevel.run(plugin='MultiProc', plugin_args={'n_procs':8})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
